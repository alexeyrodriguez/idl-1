{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_var(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_var(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.3)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, strides=[1, 1, 1, 1]):\n",
    "    return tf.nn.conv2d(x, W, strides=strides, padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_histogram(var, name):\n",
    "    with tf.name_scope('summaries'):\n",
    "        tf.summary.histogram(name, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sprite(imgs, out_path):\n",
    "    \"\"\"\n",
    "    imgs: 2D (!) numpy array containing MNIST image data (i.e. 784-length vectors).\n",
    "    out_path: Path to store sprite image at (e.g. path/to/file.png).\n",
    "    \"\"\"\n",
    "    imgs_square = imgs.reshape(-1, 28, 28)\n",
    "    grid_dim = int(np.ceil(np.sqrt(len(imgs))))\n",
    "    grid_rows = [np.concatenate(imgs_square[ind:(ind+grid_dim)], axis=1) for ind in range(0, len(imgs), grid_dim)]\n",
    "    # maybe pad last row\n",
    "    missing = grid_rows[0].shape[1] - grid_rows[-1].shape[1]\n",
    "    if missing:\n",
    "        grid_rows[-1] = np.pad(grid_rows[-1], ((0, 0), (0, missing)), mode=\"constant\")\n",
    "    grid = np.concatenate(grid_rows, axis=0)\n",
    "    # note that the images are reversed (black on white background) for readability\n",
    "    image.imsave(out_path, grid, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "# build computation graph\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "x_img = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "strides = [1, 1, 1, 1]\n",
    "\n",
    "with tf.name_scope('conv_1') as scope:\n",
    "    W_conv1 = weight_var([3, 3, 1, 32])\n",
    "    b_conv1 = bias_var([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_img, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    add_histogram(W_conv1, 'w_conv_1')\n",
    "    add_histogram(b_conv1, 'b_conv1')\n",
    "\n",
    "with tf.name_scope('conv_2') as scope:\n",
    "    W_conv2 = weight_var([7, 7, 32, 64])\n",
    "    b_conv2 = bias_var([64])\n",
    "    \n",
    "    add_histogram(W_conv2, 'w_conv_2')\n",
    "    add_histogram(b_conv2, 'b_conv_2')\n",
    "    \n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "with tf.name_scope('fc_1') as scope:\n",
    "    W_fc1 = weight_var([7*7*64, 1024])\n",
    "    b_fc1 = bias_var([1024])\n",
    "    \n",
    "    add_histogram(W_fc1, 'w_fc1')\n",
    "    add_histogram(b_fc1, 'b_fc1')\n",
    "    \n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    add_histogram(h_fc1, 'h_fc1')\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# to be run after training to assign the output of fc_1 to another variable\n",
    "# for visualization\n",
    "# embedding_vec = tf.get_variable(\"embeddings\", [500, 1024])\n",
    "# save_embeddings = tf.assign(embedding_vec, h_fc1_drop)\n",
    "    \n",
    "with tf.name_scope('output') as scope:\n",
    "    W_fc2 = weight_var([1024, 10])\n",
    "    b_fc2 = bias_var([10])\n",
    "\n",
    "    y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "        \n",
    "embedding_vec = tf.Variable([0.], name='embedding')\n",
    "save_embeddings = tf.assign(embedding_vec, h_fc1, validate_shape=False)\n",
    "        \n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_dir = '../nov13/embeddings/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding run metadata for 99\n",
      "Adding run metadata for 199\n",
      "Adding run metadata for 299\n",
      "Adding run metadata for 399\n",
      "Adding run metadata for 499\n",
      "Adding run metadata for 599\n",
      "Adding run metadata for 699\n",
      "Adding run metadata for 799\n",
      "Adding run metadata for 899\n",
      "Adding run metadata for 999\n",
      "CPU times: user 31.4 s, sys: 2.14 s, total: 33.5 s\n",
      "Wall time: 30.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "num_to_viz = 400\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sesh:\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir + '/train', sesh.graph)\n",
    "    test_writer = tf.summary.FileWriter(summaries_dir + '/test')\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding_conf = config.embeddings.add()\n",
    "    embedding_conf.tensor_name = embedding_vec.name\n",
    "    embedding_conf.metadata_path = 'metadata.tsv'\n",
    "    embedding_conf.sprite.image_path = 'sprite.jpg'\n",
    "    embedding_conf.sprite.single_image_dim.extend([28, 28])\n",
    "    projector.visualize_embeddings(test_writer, config)\n",
    "\n",
    "    sesh.run(tf.global_variables_initializer())\n",
    "    batch_size = 50\n",
    "    \n",
    "    test_xs, test_ys = mnist.test.images, mnist.test.labels\n",
    "    \n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        if i % 50 == 0: # record test set accuracy\n",
    "            summary, acc = sesh.run([merged, accuracy], feed_dict={x: test_xs, y_: test_ys, keep_prob: 1.})\n",
    "            test_writer.add_summary(summary, i)\n",
    "        else:\n",
    "            if i % 100 == 99: # record train set accuracy\n",
    "                sesh.run([save_embeddings], feed_dict={x: test_xs[:num_to_viz, :],\n",
    "                                                       y_: test_ys[:num_to_viz, :]})\n",
    "                saver.save(sesh, os.path.join(summaries_dir, \"model.ckpt\"))\n",
    "                \n",
    "                summary, _ = sesh.run([merged, train_step], \n",
    "                                      feed_dict={x: batch[0],\n",
    "                                                 y_: batch[1],\n",
    "                                                 keep_prob: 0.5},\n",
    "                                      options=run_options,\n",
    "                                      run_metadata=run_metadata)\n",
    "\n",
    "                train_writer.add_summary(summary, i)\n",
    "                print('Adding run metadata for', i)\n",
    "            else:  # Record a summary\n",
    "                sesh.run([train_step], feed_dict={x: batch[0],\n",
    "                                                 y_: batch[1],\n",
    "                                                 keep_prob: 0.5})\n",
    "        \n",
    "\n",
    "test_writer.close()\n",
    "train_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels as metadata\n",
    "with open(os.path.join(summaries_dir + '/test', 'metadata.tsv'), 'w') as fout:\n",
    "    for label in list(np.where(test_ys==1)[1][:num_to_viz]):\n",
    "        fout.write('{}\\n'.format(label))         \n",
    "        \n",
    "make_sprite(test_xs[:num_to_viz, :], os.path.join(summaries_dir + '/test', 'sprite.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

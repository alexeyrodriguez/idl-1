fail1: exploding gradient, learning rate too high
fail2: sigmoid activation saturated
fail3: relu saturated bc output layer was initialized to have max 0, so no gradient could pass through
fail4:

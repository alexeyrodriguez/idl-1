{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from nov27.prepare_data import parse_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state_size = 256\n",
    "summaries_dir = 'nov27/summaries/{}'.format(hidden_state_size)\n",
    "\n",
    "max_seq_len = 100\n",
    "prefix = 'nov27/bible/kj{}'.format(max_seq_len)\n",
    "seq_file = prefix + '.tfrecords'\n",
    "vocab_file = prefix + '_vocab'\n",
    "\n",
    "batch_size = 100\n",
    "num_epochs = 100\n",
    "\n",
    "with open(vocab_file, 'rb') as fin:\n",
    "    ch_to_idx = pickle.load(fin)\n",
    "    num_chars = len(ch_to_idx)    \n",
    "\n",
    "dataset = tf.contrib.data.TFRecordDataset([seq_file])\n",
    "dataset = dataset.map(parse_seq)\n",
    "dataset = dataset.shuffle(1000).repeat(num_epochs).padded_batch(batch_size, [None])\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cell_state = tf.placeholder(tf.float32, [batch_size, hidden_state_size])\n",
    "hidden_state = tf.placeholder(tf.float32, [batch_size, hidden_state_size])\n",
    "init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "\n",
    "with tf.name_scope(\"input\"):\n",
    "    inputs = iterator.get_next()\n",
    "\n",
    "xs = inputs[:, :-1]\n",
    "valid_xs_mask = tf.not_equal(xs, 0)\n",
    "\n",
    "xs_seq_len = tf.reduce_sum(tf.to_int32(valid_xs_mask), axis=1)\n",
    "one_hot_xs = tf.one_hot(xs, depth=num_chars)\n",
    "ys = inputs[:, 1:]\n",
    "one_hot_ys = tf.one_hot(ys, depth=num_chars)\n",
    "    \n",
    "rnn_cell = tf.nn.rnn_cell.LSTMCell(hidden_state_size, state_is_tuple=True)\n",
    "outputs, state = tf.nn.dynamic_rnn(rnn_cell, one_hot_xs, sequence_length=xs_seq_len, initial_state=init_state)\n",
    "\n",
    "with tf.variable_scope(\"output\"):\n",
    "    W_hy = tf.get_variable('W_hy', [hidden_state_size, num_chars])\n",
    "    B_hy = tf.get_variable('B_hy', [num_chars])\n",
    "    \n",
    "logits = tf.tensordot(outputs, W_hy, axes=1) + B_hy\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_ys, logits=logits)\n",
    "masked_cross_entropy = tf.multiply(cross_entropy, tf.to_float(valid_xs_mask))\n",
    "summed_entropy = tf.reduce_sum(masked_cross_entropy, 1)\n",
    "sequence_entropy = tf.divide(summed_entropy, tf.to_float(xs_seq_len))\n",
    "total_entropy = tf.reduce_mean(sequence_entropy)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer().minimize(total_entropy)\n",
    "\n",
    "tf.summary.scalar('entropy', total_entropy)\n",
    "summary_op = tf.summary.merge_all()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\tcost 4.427514553070068\n",
      "Step 100\tcost 3.019747734069824\n",
      "Step 200\tcost 2.4725136756896973\n",
      "Step 300\tcost 2.2674739360809326\n",
      "Step 400\tcost 2.1300594806671143\n",
      "Step 500\tcost 2.0357859134674072\n",
      "Step 600\tcost 1.9588953256607056\n",
      "Step 700\tcost 1.9420647621154785\n",
      "Step 800\tcost 1.8960859775543213\n",
      "Step 900\tcost 1.8563787937164307\n",
      "Step 1000\tcost 1.775043249130249\n",
      "Step 1100\tcost 1.7879135608673096\n",
      "Step 1200\tcost 1.7991793155670166\n",
      "Step 1300\tcost 1.7858997583389282\n",
      "Step 1400\tcost 1.735626220703125\n",
      "Step 1500\tcost 1.6872413158416748\n",
      "Step 1600\tcost 1.6137914657592773\n",
      "Step 1700\tcost 1.667502522468567\n",
      "Step 1800\tcost 1.6832202672958374\n",
      "Step 1900\tcost 1.627293586730957\n",
      "Step 2000\tcost 1.5775028467178345\n",
      "Step 2100\tcost 1.5419609546661377\n",
      "Step 2200\tcost 1.5398194789886475\n",
      "Step 2300\tcost 1.5281741619110107\n",
      "Step 2400\tcost 1.5041083097457886\n",
      "Step 2500\tcost 1.4725151062011719\n",
      "Step 2600\tcost 1.5203986167907715\n",
      "Step 2700\tcost 1.5064752101898193\n",
      "Step 2800\tcost 1.5421086549758911\n",
      "Step 2900\tcost 1.3868204355239868\n",
      "Step 3000\tcost 1.3800956010818481\n",
      "Step 3100\tcost 1.4317699670791626\n",
      "Step 3200\tcost 1.4456214904785156\n",
      "Step 3300\tcost 1.411816954612732\n",
      "Step 3400\tcost 1.3548474311828613\n",
      "Step 3500\tcost 1.3360400199890137\n",
      "Step 3600\tcost 1.3620667457580566\n",
      "Step 3700\tcost 1.316382646560669\n",
      "Step 3800\tcost 1.297339677810669\n",
      "Step 3900\tcost 1.3276498317718506\n",
      "Step 4000\tcost 1.3442023992538452\n",
      "Step 4100\tcost 1.3982220888137817\n",
      "Step 4200\tcost 1.3485901355743408\n",
      "Step 4300\tcost 1.2511727809906006\n",
      "Step 4400\tcost 1.243304967880249\n",
      "Step 4500\tcost 1.2629681825637817\n",
      "Step 4600\tcost 1.2805042266845703\n",
      "Step 4700\tcost 1.2661669254302979\n",
      "Step 4800\tcost 1.2678946256637573\n",
      "Step 4900\tcost 1.2729487419128418\n",
      "Step 5000\tcost 1.2947248220443726\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sesh:\n",
    "    writer = tf.summary.FileWriter(summaries_dir, sesh.graph)\n",
    "    sesh.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(5000+1):\n",
    "        _ = sesh.run([train_op], feed_dict={\n",
    "                         hidden_state: np.zeros([batch_size, hidden_state_size]),\n",
    "                         cell_state: np.zeros([batch_size, hidden_state_size])\n",
    "                     })\n",
    "        if step % 100 == 0:\n",
    "            cost, summary, _ = sesh.run([total_entropy, summary_op, train_op], feed_dict={\n",
    "                hidden_state: np.zeros((batch_size, hidden_state_size)),\n",
    "                cell_state: np.zeros((batch_size, hidden_state_size))})\n",
    "            \n",
    "            writer.add_summary(summary, step)\n",
    "            print(\"Step {}\\tcost {}\".format(step, cost))\n",
    "        if step % 1000 == 0:\n",
    "            saver.save(sesh, summaries_dir + \"/model.ckpt\", global_step=step)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "summaries_dir = 'nov27/summaries/{}/'.format(hidden_state_size)\n",
    "max_seq_len = 100\n",
    "prefix = 'nov27/bible/kj{}'.format(max_seq_len)\n",
    "seq_file = prefix + '.tfrecords'\n",
    "vocab_file = prefix + '_vocab'\n",
    "\n",
    "batch_size = 100\n",
    "num_epochs = 100\n",
    "\n",
    "with open(vocab_file, 'rb') as fin:\n",
    "    ch_to_idx = pickle.load(fin)\n",
    "    num_chars = len(ch_to_idx) \n",
    "    idx_to_ch = {v: k for k, v in ch_to_idx.items()}\n",
    "\n",
    "start_char = '<S>'\n",
    "stop_char = '</S>'\n",
    "    \n",
    "dataset = tf.contrib.data.TFRecordDataset([seq_file])\n",
    "dataset = dataset.map(parse_seq)\n",
    "dataset = dataset.shuffle(1000).repeat(num_epochs).padded_batch(batch_size, [None])\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cell_state = tf.placeholder(tf.float32, [None, hidden_state_size])\n",
    "hidden_state = tf.placeholder(tf.float32, [None, hidden_state_size])\n",
    "init_state = tf.nn.rnn_cell.LSTMStateTuple(cell_state, hidden_state)\n",
    "\n",
    "input_char = tf.placeholder(tf.float32, [None, None, num_chars])\n",
    "    \n",
    "rnn_cell = tf.nn.rnn_cell.LSTMCell(hidden_state_size, state_is_tuple=True)\n",
    "outputs, state = tf.nn.dynamic_rnn(rnn_cell, input_char, sequence_length=[1], initial_state=init_state)\n",
    "\n",
    "with tf.variable_scope(\"output\"):\n",
    "    W_hy = tf.get_variable('W_hy', [hidden_state_size, num_chars])\n",
    "    B_hy = tf.get_variable('B_hy', [num_chars])\n",
    "    \n",
    "logits = tf.tensordot(outputs, W_hy, axes=1) + B_hy\n",
    "probs_op = tf.nn.softmax(logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from nov27/summaries/256/model.ckpt-5000\n",
      " And when the LORD spead to pering to her unto thempinion be\n",
      "praised her spake.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = summaries_dir + \"model.ckpt-5000\"\n",
    "\n",
    "output = ''\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sesh:\n",
    "    saver.restore(sesh, model_path)\n",
    "    \n",
    "    # init\n",
    "    cur_char = start_char\n",
    "    cur_char_vec = np.zeros((1, 1, num_chars))\n",
    "    cur_char_pos = ch_to_idx[start_char]\n",
    "    cur_char_vec[0, 0, cur_char_pos] = 1.\n",
    "    \n",
    "    cur_hidden_state = np.zeros((1, hidden_state_size))\n",
    "    cur_output_state= np.zeros((1, hidden_state_size))\n",
    "    \n",
    "    while True:\n",
    "        probs, cur_state = sesh.run([probs_op, state], feed_dict={\n",
    "            input_char: cur_char_vec,\n",
    "            cell_state: cur_output_state,\n",
    "            hidden_state: cur_hidden_state,\n",
    "        })\n",
    "        probs = np.squeeze(probs)\n",
    "        cur_char_pos = np.random.choice(num_chars, p=probs)\n",
    "        cur_char = idx_to_ch[cur_char_pos]\n",
    "        \n",
    "        if cur_char == stop_char:\n",
    "            break\n",
    "            \n",
    "        output +=  cur_char\n",
    "        \n",
    "        cur_char_vec = np.zeros((1, 1, num_chars))\n",
    "        cur_char_vec[0, 0, cur_char_pos] = 1.\n",
    "        cur_output_state, cur_hidden_state = cur_state\n",
    "            \n",
    "print(output[:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
